---
title: Logistic回归初步
date: 2021-02-12 18:27:47
categories: 机器学习
mathjax: true
tags: 
- 机器学习
- 数理
---

咕了好长时间的Logistic回归, 今天晚上不小心睡着了现在不困就写一点.

<!--more-->

Logistic回归主要是解决二分类问题,  普通的线性拟合拟合出的函数值域是实数集, 通过套一个激活函数就可以把这个实数集映射到上$[0,1]$.

常见的激活函数之一是Sigmoid函数:

$$ S(x) = \frac{1}{1+e^{-x}} $$

这个函数有个性质, 就是求导之后可以用原函数的一个简单的多项式表达, 一会推导的时候有用:

$$ S'(x) = S(x)(1-S(x)) $$

然后就可以用之前的线性拟合套一个这个函数拟合, 因为这个函数可导, 推导过程和线性拟合的推导过程差不多.

如果反过来写, 把$y = S(w^T x)$的$x$解出来, 可以写成:

$$ ln \frac{y}{1-y} = w^T x $$

其中这个$ln \frac{y}{1-y}$又叫对数几率, $y$是概率, 在$[0,1]$上, 通过这个函数映射到$R$上, 实际上Logistic回归就是用线性拟合去拟合对数几率.

关于Loss函数, 有些文章直接给出了这个Loss函数的表达式, 然后简单的定性说明一下, 实际上这个函数就是极大似然函数. (只在期末考试前学了一天概率论的我记住的为数不多的东西)

对线性拟合的系数矩阵进行极大似然估计, 写出似然函数$L(w)$, 然后求个导就能用梯度下降了. 推导过程就不写Latex了, 太麻烦了, 放一个我之前自己推导的草稿吧.

![img](/img/logistic-basis/image.png)



还有, Sigmoid函数是任意阶可导的, 所以牛顿法也是可以用的.

下面都是我瞎想口胡的, 还没来得及验证.

Logistic回归是解决二分类问题的, 得到的结果是一个点属于其中一类的概率. 顺着这个思路, 我想如果把里面的一个数改成一个向量, 然后函数得到的结果是也是一个向量, 向量的每一个元素代表这个点属于这个类的概率, 这样就可以解决多分类问题了. 

按照Logistic回归的想法, 首先得到的是一个在$R$上的数, 在我这个多分类模型的想法中, 首先就要得到一个$R^n$的向量, 其中每一个元素都是单独线性拟合出的结果. 然后对这个向量加一个激活函数, 就可以得到最终的结果向量. 这个激活函数需要把一个$R^n$的向量映射到一个$[0,1]^n$的向量, 并且这个向量元素加起来等于1. 查了一下, 都用的softmax做到这个.

Loss函数也按照极大似然估计的思路来推, 应该就可以实现多分类了, 有时间去试验一下. 